import subprocess
import os
import whisper
import google.generativeai as genai
import feedparser
from datetime import datetime, timedelta, timezone
import pandas as pd # å°å…¥ pandas å‡½å¼åº«
from google.colab import userdata

data = {
    "Channel": [
        "TODAY çœ‹ä¸–ç•Œ", "éå‡¡æ–°è", "å †é‡‘ç©ç‰", "90å¾Œå‰µæ¥­å®¶æƒåœ°åƒ§", "Emmyè¿½åŠ‡æ™‚é–“", "Better Leaf å¥½è‘‰", "å•Ÿé»æ–‡åŒ–",
        "å•†æ¥­å‘¨åˆŠ", "cheap", "è¶…ç´šæˆ¿ä»²å­¸é™¢", "å°Linè¯´", "Wisdom Bread æ™ºæ…§éºµåŒ…", "Lester èŠæ–¯ç‰¹", "è£ä¿®å°æ­¦éƒ",
        "PanSci æ³›ç§‘å­¸", "æœ¬å­åœ¨éš”å£ Benzi", "å–µæ˜Ÿå¾‹å¸«-æ–½å®‡å®¸", "æ›²åšç§‘æŠ€æ•™å®¤", "è²¡è¨Š", "èŒƒçªæ–çš„ç¾åœ‹æ™‚é–“",
        "è’¼è—é´¿çš„é†«å­¸å¤©åœ°", "TED"
    ],
    "Channel_id": [
        "UCmMnzrvnsSnv-0u9M1Rxiqw", "UCYIVkruUoN04UjV9pkBTswg", "UCeXxT_PoNOzS5dMOmmNk-6A", "UCWMxmoBhchU3swFAciqagnw",
        "UCUkwvRrpvWkocNdk9qIpRSw", "UChjHWpmNm-3HbLFkQ3TPXaA", "UCywBTF8MXwyQU21F1vHMnfw", "UCwlpC8vX_GkRngPYSnwkJxg",
        "UCGGrblndNzi86WY5lJkQJiA", "UCvj1qp0qh7VQY4Bz5VGdCVA", "UCilwQlk62k1z7aUEZPOB6yw", "UC-qwAKnBVzUlbNwol3UCZIA",
        "UCOI5JDEGupfDv5whYzlthPQ", "UCHDok5IzApSeLOJHHhqey8A", "UCuHHKbwC0TWjeqxbqdO-N_g", "UC-J5ksuTsGzqAbemiLRgcSw",
        "UCBkLBa86e5kscEGkZDyNxQQ", "UCq8Xi8muhehxRMIK76I1jog", "UCh2hilgoPIY-kiy1yFCc-xA", "UC2VKL-DkRvXtWkfjMzkYvmw",
        "UCUn77_F5A65HViL9OEvIpLw", "UCAuUUnT6oDeKwE6v1NGQxug"
    ]
}

channel = pd.DataFrame(data)

def get_new_youtube_videos_last_week_as_dataframe(rss_url, information=False, day_back_track=1):
    try:
        feed = feedparser.parse(rss_url)

        if not feed.entries:
            print("æ²’æœ‰æ‰¾åˆ°å½±ç‰‡æˆ–RSS Feedè§£æå¤±æ•—ã€‚")
            return pd.DataFrame() # è¿”å›ç©ºçš„ DataFrame

        videos_data = [] # ç”¨ä¾†å„²å­˜å½±ç‰‡è³‡è¨Šçš„åˆ—è¡¨

        # å–å¾—ç•¶å‰æ™‚é–“ä¸¦è¨ˆç®—ä¸€é€±å‰çš„æ™‚é–“
        now = datetime.now(timezone.utc)
        day_ago = now - timedelta(days=day_back_track)

        print(f"æ­£åœ¨å¾ {rss_url} æª¢æŸ¥è¿‘{day_back_track}å¤©çš„æ–°å½±ç‰‡ (å¾ {day_ago.strftime('%Y-%m-%d %H:%M:%S %Z')} åˆ° {now.strftime('%Y-%m-%d %H:%M:%S %Z')})...")

        for entry in feed.entries:
            title = entry.get('title')
            link = entry.get('link')
            published_parsed = entry.get('published_parsed') # å½±ç‰‡ç™¼å¸ƒæ™‚é–“ï¼Œè§£æç‚ºstruct_time

            if published_parsed:
                # å°‡ struct_time è½‰æ›ç‚º datetime ç‰©ä»¶ï¼Œä¸¦è¨­å®šç‚ºUTCæ™‚å€
                published_dt = datetime(*published_parsed[:6], tzinfo=timezone.utc)

                # æª¢æŸ¥å½±ç‰‡ç™¼å¸ƒæ™‚é–“æ˜¯å¦åœ¨ä¸€é€±å…§
                if published_dt >= day_ago and published_dt <= now:
                    # if information:
                    #     print(f"  ç™¼ç¾æ–°å½±ç‰‡ï¼ˆè¿‘ä¸€é€±å…§ï¼‰ï¼š")
                    #     print(f"    æ¨™é¡Œ: {title}")
                    #     print(f"    é€£çµ: {link}")
                    #     print(f"    ç™¼å¸ƒæ™‚é–“: {published_dt.strftime('%Y-%m-%d %H:%M:%S %Z')}")
                    #     print("-" * 30)

                    # å°‡å½±ç‰‡è³‡è¨ŠåŠ å…¥åˆ°åˆ—è¡¨ä¸­
                    videos_data.append({
                        'Title': title,
                        'Link': link,
                        'Published_At': published_dt.strftime('%Y-%m-%d %H:%M:%S %Z') # ä»¥å­—ä¸²æ ¼å¼å„²å­˜æ™‚é–“
                        # å¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥å„²å­˜åŸå§‹çš„ datetime ç‰©ä»¶: 'Published_Datetime_Object': published_dt
                    })
            else:
                print(f"è­¦å‘Šï¼šå½±ç‰‡ '{title}' ç¼ºå°‘ç™¼å¸ƒæ™‚é–“è³‡è¨Šï¼Œç„¡æ³•åˆ¤æ–·æ˜¯å¦ç‚ºè¿‘ä¸€é€±å½±ç‰‡ã€‚")

        if not videos_data:
            print("è¿‘ä¸€é€±å…§æ²’æœ‰æ‰¾åˆ°æ–°å½±ç‰‡ã€‚")

        # å°‡åˆ—è¡¨è½‰æ›ç‚º Pandas DataFrame
        df = pd.DataFrame(videos_data)
        return df

    except Exception as e:
        print(f"è§£æRSS Feedæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame() # å‡ºéŒ¯æ™‚è¿”å›ç©ºçš„ DataFrame

# --- ä¸»è¦å‡½å¼ï¼šè™•ç†å¤šå€‹é »é“ä¸¦åŠ å…¥é »é“åç¨± ---
def get_recent_videos_with_channel_names(channels_df, day_back_track=1):
    """
    æ¥æ”¶ä¸€å€‹åŒ…å« 'Channel' å’Œ 'Channel_id' çš„ DataFrameï¼Œ
    æŠ“å–æ¯å€‹é »é“è¿‘ä¸€é€±çš„æ–°å½±ç‰‡ï¼Œä¸¦å°‡é »é“åç¨±åŠ å…¥çµæœ DataFrame ä¸­ã€‚

    Args:
        channels_df (pd.DataFrame): åŒ…å«ä»¥ä¸‹å…©åˆ—çš„ DataFrameï¼š
                                    - 'Channel': é »é“åç¨± (str)
                                    - 'Channel_id': é »é“ RSS Feed ç¶²å€ (str)

    Returns:
        pd.DataFrame: åŒ…å«æ‰€æœ‰é »é“è¿‘ä¸€é€±æ–°å½±ç‰‡çš„ DataFrameï¼Œ
                      é¡å¤–åŒ…å« 'Channel_Name' æ¬„ä½ã€‚
    """
    youtube_base_url = "https://www.youtube.com/feeds/videos.xml?channel_id="
    all_recent_videos = [] # ç”¨ä¾†å„²å­˜æ‰€æœ‰é »é“çš„æ–°å½±ç‰‡è³‡æ–™

    if channels_df.empty:
        print("è¼¸å…¥çš„ channels_df æ˜¯ç©ºçš„ï¼Œæ²’æœ‰é »é“å¯ä»¥è™•ç†ã€‚")
        return pd.DataFrame()

    for index, row in channels_df.iterrows():
        channel_name = row['Channel']
        channel_url = youtube_base_url + row['Channel_id']

        print(f"--- æ­£åœ¨è™•ç†é »é“ï¼š {channel_name} ({channel_url}) ---")

        # å‘¼å«ä¹‹å‰çš„å‡½å¼ä¾†æŠ“å–å–®ä¸€é »é“çš„æ–°å½±ç‰‡
        recent_videos_for_channel = get_new_youtube_videos_last_week_as_dataframe(channel_url, day_back_track=day_back_track)

        if not recent_videos_for_channel.empty:
            # å°‡é »é“åç¨±é€™ä¸€åˆ—æ·»åŠ åˆ°ç•¶å‰é »é“çš„å½±ç‰‡ DataFrame ä¸­
            recent_videos_for_channel['Channel_Name'] = channel_name

            # å°‡é€™å€‹é »é“çš„å½±ç‰‡è³‡æ–™æ·»åŠ åˆ°ç¸½åˆ—è¡¨
            all_recent_videos.append(recent_videos_for_channel)
            print(f"  é »é“ {channel_name} æ‰¾åˆ° {len(recent_videos_for_channel)} éƒ¨è¿‘{day_back_track}å¤©æ–°å½±ç‰‡ã€‚")
        else:
            print(f"  é »é“ {channel_name} è¿‘{day_back_track}å¤©æ²’æœ‰æ–°å½±ç‰‡ã€‚")
        print("-" * 50) # åˆ†éš”ç·š

    if all_recent_videos:
        # å°‡æ‰€æœ‰é »é“çš„ DataFrame åˆä½µæˆä¸€å€‹å¤§çš„ DataFrame
        final_df = pd.concat(all_recent_videos, ignore_index=True)
        return final_df
    else:
        print("æ‰€æœ‰é »é“åœ¨è¿‘ä¸€é€±å…§éƒ½æ²’æœ‰æ‰¾åˆ°æ–°å½±ç‰‡ã€‚")
        return pd.DataFrame() # å¦‚æœæ²’æœ‰ä»»ä½•å½±ç‰‡ï¼Œå‰‡è¿”å›ä¸€å€‹ç©ºçš„ DataFrame


def append_unique_videos(new_df: pd.DataFrame, old_df: pd.DataFrame) -> pd.DataFrame:
    """
    å°‡æ–°çš„å½±ç‰‡è³‡æ–™ (new_df) ä¸­ä¸é‡è¤‡çš„æ¢ç›®è¿½åŠ åˆ°ç¾æœ‰å½±ç‰‡è³‡æ–™ (old_df) ä¸­ã€‚

    é‡è¤‡çš„åˆ¤æ–·ä¾æ“šç‚º 'Title', 'Link', 'Published_At', 'Channel_Name'ã€‚
    æ–°è¿½åŠ çš„å½±ç‰‡æ¢ç›®æœƒè‡ªå‹•ç²å¾— 'Used' æ¬„ä½ä¸¦é è¨­ç‚º Falseã€‚

    Args:
        new_df (pd.DataFrame): åŒ…å«æ–°å½±ç‰‡è³‡è¨Šçš„ DataFrameï¼Œæ‡‰åŒ…å« 'Title', 'Link', 'Published_At', 'Channel_Name'ã€‚
        old_df (pd.DataFrame): åŒ…å«èˆŠå½±ç‰‡è³‡è¨Šçš„ DataFrameï¼Œæ‡‰åŒ…å« 'Title', 'Link', 'Published_At', 'Channel_Name', 'Used'ã€‚

    Returns:
        pd.DataFrame: åˆä½µå¾Œä¸”å·²å»é‡ï¼ˆåŒ…å«æ‰€æœ‰ä¸é‡è¤‡å½±ç‰‡ï¼‰çš„ DataFrameã€‚
    """

    # å®šç¾©ç”¨æ–¼åˆ¤æ–·é‡è¤‡çš„é—œéµæ¬„ä½
    identifying_cols = ['Title', 'Link', 'Published_At', 'Channel_Name']

    # æª¢æŸ¥ new_df æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦çš„è­˜åˆ¥æ¬„ä½
    if not all(col in new_df.columns for col in identifying_cols):
        print("éŒ¯èª¤ï¼šnew_df ç¼ºå°‘å¿…è¦çš„è­˜åˆ¥æ¬„ä½ã€‚è«‹ç¢ºä¿å®ƒåŒ…å« 'Title', 'Link', 'Published_At', 'Channel_Name'ã€‚")
        return old_df # å¦‚æœ new_df æ ¼å¼ä¸æ­£ç¢ºï¼Œå‰‡è¿”å›åŸä¾†çš„ old_df

    # ç‚ºäº†æ–¹ä¾¿åˆ¤æ–·é‡è¤‡ï¼Œç‚ºå…©å€‹ DataFrame å»ºç«‹ä¸€å€‹è‡¨æ™‚çš„å”¯ä¸€éµ
    # å°‡æ‰€æœ‰è­˜åˆ¥æ¬„ä½çš„å€¼é€£æ¥æˆä¸€å€‹å­—ä¸²ä½œç‚ºéµ
    new_df['__temp_key__'] = new_df[identifying_cols].astype(str).agg(''.join, axis=1)
    old_df['__temp_key__'] = old_df[identifying_cols].astype(str).agg(''.join, axis=1)

    # æ‰¾å‡º new_df ä¸­é‚£äº› '__temp_key__' ä¸å­˜åœ¨æ–¼ old_df çš„è¡Œ
    # é€™äº›å°±æ˜¯æˆ‘å€‘æƒ³è¦è¿½åŠ çš„ã€ŒçœŸæ­£æ–°ã€çš„å½±ç‰‡è³‡æ–™
    truly_new_entries_df = new_df[~new_df['__temp_key__'].isin(old_df['__temp_key__'])].copy()

    # ç‚ºé€™äº›çœŸæ­£æ–°çš„å½±ç‰‡æ¢ç›®æ·»åŠ  'Used' æ¬„ä½ï¼Œä¸¦é è¨­ç‚º False
    # å› ç‚ºå®ƒå€‘æ˜¯æ–°çš„ï¼Œå°šæœªè¢«ä½¿ç”¨
    if 'Used' not in truly_new_entries_df.columns:
        truly_new_entries_df['Used'] = False

    # ç¢ºä¿ truly_new_entries_df åªåŒ…å« old_df ä¸­å·²æœ‰çš„æ¬„ä½ï¼Œä¸¦ä¸”é †åºä¸€è‡´
    # é€™æ¨£åœ¨åˆä½µæ™‚å¯ä»¥é¿å…é¡å¤–çš„ NaN æˆ–æ¬„ä½é †åºå•é¡Œ
    final_cols_order = old_df.columns.tolist()

    # é¸æ“‡ truly_new_entries_df ä¸­ old_df æ‰€æ“æœ‰çš„æ¬„ä½ï¼Œä¸¦ç¢ºä¿å®ƒå€‘æŒ‰ old_df çš„é †åºæ’åˆ—
    # ç§»é™¤è‡¨æ™‚éµä¹‹å‰è™•ç†å¥½æ¬„ä½
    cols_to_select = [col for col in final_cols_order if col in truly_new_entries_df.columns]
    truly_new_entries_df = truly_new_entries_df[cols_to_select]

    # ç§»é™¤è‡¨æ™‚çš„ '__temp_key__' æ¬„ä½
    truly_new_entries_df.drop(columns=['__temp_key__'], inplace=True)
    old_df.drop(columns=['__temp_key__'], inplace=True)

    # ä½¿ç”¨ concat å°‡ç¾æœ‰è³‡æ–™ (old_df) å’ŒçœŸæ­£çš„æ–°è³‡æ–™ (truly_new_entries_df) åˆä½µ
    # ignore_index=True æœƒé‡ç½®ç´¢å¼•ï¼Œç¢ºä¿çµæœ DataFrame çš„ç´¢å¼•æ˜¯é€£çºŒçš„
    combined_df = pd.concat([old_df, truly_new_entries_df], ignore_index=True)

    print(f"å·²å¾ {len(new_df)} ç­†æ–°è³‡æ–™ä¸­æ‰¾åˆ° {len(truly_new_entries_df)} ç­†å”¯ä¸€æ–°å½±ç‰‡ã€‚")
    print(f"æœ€çµ‚ DataFrame åŒ…å« {len(combined_df)} ç­†è¨˜éŒ„ã€‚")

    return combined_df

# channel = pd.read_csv('Suscribe.csv')
recent_videos_df = get_recent_videos_with_channel_names(channel)

if not recent_videos_df.empty:
    print(f"\næˆåŠŸå–å¾— {len(recent_videos_df)} éƒ¨çš„æ–°å½±ç‰‡")

else:
    print("\næ²’æœ‰æ‰¾åˆ°ä»»ä½•çš„æ–°å½±ç‰‡ï¼Œæˆ–åœ¨ç²å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ã€‚")
# old = pd.read_csv('Channel_list.csv')
# saving = append_unique_videos(recent_videos_df, old)
# å„²å­˜çµæœåˆ° CSV æª”æ¡ˆ
# saving.to_csv('Channel_list.csv', index=False, encoding='utf-8-sig')

def use_url_check_transcript(youtube_url):
  print("ç”¨ Whisper åˆ†æéŸ³è¨Š...")
  subprocess.run(f'yt-dlp -f bestaudio --extract-audio --audio-format mp3 -o "audio.%(ext)s" "{youtube_url}"', shell=True)
  audio_file = None
  for file in os.listdir():
      if file.endswith(".mp3"):
          audio_file = file
          break
  model = whisper.load_model("small")  # å¯æ”¹ tiny / base / medium
  result = model.transcribe(audio_file)
  transcript = result["text"]

  # åˆªé™¤éŸ³è¨Šæª”æ¡ˆ
  if audio_file and os.path.exists(audio_file):
      os.remove(audio_file)
  return transcript

def use_transcript_get_summary(transcript):
  import google.generativeai as genai

  # è¨­å®š Gemini API é‡‘é‘°
  genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))

  model = genai.GenerativeModel("gemini-1.5-flash")

  response = model.generate_content(f"""
  è«‹å¹«æˆ‘å°‡ä»¥ä¸‹å½±ç‰‡é€å­—ç¨¿é€²è¡Œæ‘˜è¦ï¼Œæ¢åˆ—å¼åˆ—å‡ºé‡é»ã€‚å…§å®¹å¦‚ä¸‹ï¼š
  {transcript}
  """)

  # print("\nğŸ“Œ Gemini æ‘˜è¦çµæœï¼š")
  # print(response.text)
  return response.text

def use_url_get_summary(url):
  transcript = use_url_check_transcript(url)
  summary = use_transcript_get_summary(transcript)
  return summary

def processing_link(link: str) -> bool:
    """
    é€™å€‹æ˜¯ä¸€å€‹ç¯„ä¾‹å‡½å¼ï¼Œç”¨æ–¼æ¨¡æ“¬è™•ç†å½±ç‰‡é€£çµã€‚
    æ‚¨éœ€è¦å°‡æ­¤å‡½å¼æ›¿æ›ç‚ºæ‚¨å¯¦éš›çš„å½±ç‰‡é€£çµè™•ç†é‚è¼¯ã€‚

    Args:
        link (str): å½±ç‰‡çš„é€£çµã€‚

    Returns:
        bool: å¦‚æœé€£çµè™•ç†æˆåŠŸè¿”å› Trueï¼Œå¦å‰‡è¿”å› Falseã€‚
              é€™å€‹è¿”å›å€¼æœƒå½±éŸ¿ 'Used' æ¬„ä½æ˜¯å¦è¢«æ›´æ–°ã€‚
    """
    print(f"æ­£åœ¨è™•ç†é€£çµ: {link}")
    summary = use_url_get_summary(link)
    return True, summary

def process_unused_videos_and_update_status(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ‰¾å‡º DataFrame ä¸­ 'Used' æ¬„ä½ç‚º False çš„å½±ç‰‡ï¼Œ
    å°å…¶é€£çµåŸ·è¡Œ processing_link å‡½å¼ï¼Œç„¶å¾Œå°‡ 'Used' ç‹€æ…‹æ›´æ–°ç‚º Trueã€‚

    Args:
        df (pd.DataFrame): åŒ…å«å½±ç‰‡è³‡è¨Šçš„ DataFrameï¼Œæ‡‰åŒ…å« 'Title', 'Link', 'Published_At', 'Channel_Name', 'Used'ã€‚

    Returns:
        pd.DataFrame: æ›´æ–° 'Used' ç‹€æ…‹å¾Œçš„ DataFrameã€‚
    """

    if 'Used' not in df.columns:
        print("éŒ¯èª¤ï¼šDataFrame ä¸­æ²’æœ‰ 'Used' æ¬„ä½ã€‚ç„¡æ³•åŸ·è¡Œæ“ä½œã€‚")
        return df

    # ç¯©é¸å‡ºæ‰€æœ‰ 'Used' æ¬„ä½ç‚º False çš„å½±ç‰‡
    unused_videos = df[df['Used'] == False]

    if unused_videos.empty:
        print("ç›®å‰æ²’æœ‰ä»»ä½• 'Used' æ¬„ä½ç‚º False çš„å½±ç‰‡éœ€è¦è™•ç†ã€‚")
        return df # å¦‚æœæ²’æœ‰æœªä½¿ç”¨çš„å½±ç‰‡ï¼Œç›´æ¥è¿”å›åŸå§‹ DataFrame
    new_summary = {}
    print(f"æ‰¾åˆ° {len(unused_videos)} ç­† 'Used' æ¬„ä½ç‚º False çš„å½±ç‰‡ï¼Œæº–å‚™è™•ç†ã€‚")

    # éæ­·é€™äº›æœªä½¿ç”¨çš„å½±ç‰‡ï¼Œä¸¦å°å…¶é€£çµé€²è¡Œè™•ç†
    # ä½¿ç”¨ .loc é€²è¡ŒåŸºæ–¼æ¨™ç±¤çš„é¸æ“‡å’Œæ›´æ–°ï¼Œä»¥é¿å… SettingWithCopyWarning
    for index, row in unused_videos.iterrows():
        video_link = row['Link']
        title = row['Title']

        try:
          # å‘¼å«æ‚¨çš„ processing_link å‡½å¼ä¾†è™•ç†é€£çµ
          process_successful, summary = processing_link(video_link)
          print(title)
          print(video_link)
          print(summary)
          print('-'*30)

          # å¦‚æœè™•ç†æˆåŠŸï¼Œå‰‡å°‡è©²ç­†å½±ç‰‡çš„ 'Used' ç‹€æ…‹æ›´æ–°ç‚º True
          if process_successful:
              df.loc[index, 'Used'] = True
              print(f"å½±ç‰‡ '{row['Title']}' çš„ 'Used' ç‹€æ…‹å·²æ›´æ–°ç‚º Trueã€‚")
              new_summary[title] = [video_link, summary]
          else:
              print(f"å½±ç‰‡ '{row['Title']}' è™•ç†å¤±æ•—ï¼Œ'Used' ç‹€æ…‹ä¿æŒ Falseã€‚")
        except:
          # é‡åˆ°å•é¡Œ å¼·åˆ¶è©²rowè½‰ç‚ºTrue
          df.loc[index, 'Used'] = True
          print(f"å½±ç‰‡ '{row['Title']}' çš„ 'Used' ç‹€æ…‹å·²æ›´æ–°ç‚º Trueã€‚")
          continue
        finally:
          print("-" * 30)

    print("æ‰€æœ‰æœªä½¿ç”¨çš„å½±ç‰‡è™•ç†å®Œæˆã€‚")
    return df, new_summary

print(f'è¿‘æœŸæœ‰{len(recent_videos_df)}å€‹æ›´æ–°')
recent_videos_df.head()

recent_videos_df['Used'] = False
updated_videos_df, new_summary = process_unused_videos_and_update_status(recent_videos_df)

import smtplib
import ssl
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import os
import datetime # å°å…¥ datetime æ¨¡çµ„ä¾†ç²å–ç•¶å‰æ—¥æœŸ

# --- é…ç½®å€ --- è«‹ä¿®æ”¹ä»¥ä¸‹è³‡è¨Š ---

# ä½ çš„ç™¼ä»¶äºº Gmail éƒµç®±åœ°å€
# ç¯„ä¾‹: "your_robot_email@gmail.com"
# è«‹ç¢ºä¿é€™å€‹ Gmail å¸³æˆ¶å·²é–‹å•Ÿã€Œå…©æ­¥é©Ÿé©—è­‰ã€ï¼Œä¸¦ä¸”ä½ ç‚ºæ­¤å¸³æˆ¶ç”Ÿæˆäº†ã€Œæ‡‰ç”¨ç¨‹å¼å¯†ç¢¼ã€ã€‚
SENDER_EMAIL = userdata.get('GOOGLE_MAIL')

# ä½ å¾ Google å¸³æˆ¶å®‰å…¨æ€§è¨­å®šä¸­ç²å¾—çš„ 16 ä½ã€Œæ‡‰ç”¨ç¨‹å¼å¯†ç¢¼ã€ã€‚
# é€™æ˜¯ Gmail å°ˆé–€ç‚ºç¬¬ä¸‰æ–¹æ‡‰ç”¨ç¨‹å¼æä¾›çš„å¯†ç¢¼ï¼Œä¸æ˜¯ä½  Gmail çš„ä¸»å¯†ç¢¼ã€‚
# ç¯„ä¾‹: "abcd efgh ijkl mnop" (æ³¨æ„ï¼Œè¤‡è£½æ™‚é€šå¸¸æ²’æœ‰ç©ºæ ¼)
SENDER_PASSWORD = userdata.get('GOOGLE_MAIL_KEY')

# æ”¶ä»¶äººéƒµç®±åœ°å€ (å¯ä»¥æ˜¯ä½ çš„ä¸»è¦éƒµç®±ï¼Œä¾‹å¦‚ä½ çš„ Outlook éƒµç®±)
# ç¯„ä¾‹: "my_main_email@outlook.com"
RECEIVER_EMAIL = userdata.get('RECEIVER_Mail')

# éƒµä»¶ä¸»é¡Œ
# ä½¿ç”¨ datetime æ¨¡çµ„è‡ªå‹•ç²å–ç•¶å‰æ—¥æœŸï¼Œè®“éƒµä»¶ä¸»é¡Œæ›´å‹•æ…‹ã€‚
current_date = datetime.date.today().strftime("%Y-%m-%d")
EMAIL_SUBJECT = f"Python æ©Ÿå™¨äººæ–°èæ‘˜è¦ - {current_date}"

# æ˜¯å¦åŒ…å«é™„ä»¶ (True/False)
ATTACH_FILE = False
# å¦‚æœè¦åŒ…å«é™„ä»¶ï¼Œè«‹æŒ‡å®šé™„ä»¶çš„è·¯å¾‘å’Œæª”æ¡ˆåç¨±
# ç¯„ä¾‹: "D:/MyDocuments/news_report.pdf" æˆ– "summary_20250609.txt"
# è«‹ç¢ºä¿é€™å€‹æª”æ¡ˆç¢ºå¯¦å­˜åœ¨æ–¼æŒ‡å®šè·¯å¾‘ã€‚
ATTACHMENT_PATH = "ä½ çš„é™„ä»¶æª”æ¡ˆè·¯å¾‘.txt"

# --- SMTP ä¼ºæœå™¨é…ç½® (é€™æ˜¯ Gmail çš„è¨­å®šï¼Œè«‹å‹¿ä¿®æ”¹) ---
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587 # Gmail çš„ TLS ç«¯å£

# éƒµä»¶æ­£æ–‡å…§å®¹ (ç›®å‰è¨­å®šç‚ºç´”æ–‡å­—ã€‚å¦‚æœä½ æƒ³ç™¼é€ HTML éƒµä»¶ï¼Œéœ€è¦èª¿æ•´ MIMEText çš„ç¬¬äºŒå€‹åƒæ•¸ç‚º "html")
# --- æ ¼å¼åŒ–æ–°èæ‘˜è¦å…§å®¹ ---
# é€™å€‹éƒ¨åˆ†å°‡ new_summary å­—å…¸è½‰æ›æˆå¤šè¡Œå­—ä¸²
formatted_news_content = []
for title, details in new_summary.items():
    link = details[0]
    summary_text = details[1]
    formatted_news_content.append(f"æ¨™é¡Œ: {title}")
    formatted_news_content.append(f"æ‘˜è¦: {summary_text}")
    formatted_news_content.append(f"è©³æƒ…: {link}")
    formatted_news_content.append("-" * 40) # åˆ†éš”ç·š
# ä½¿ç”¨ '\n'.join() å°‡æ‰€æœ‰æ ¼å¼åŒ–å¾Œçš„è¡Œé€£æ¥æˆä¸€å€‹å–®ä¸€å­—ä¸²
formatted_news_string = "\n".join(formatted_news_content)

# ä½ å¯ä»¥æŠŠæ–°èæ‘˜è¦æ”¾åœ¨é€™è£¡ã€‚
EMAIL_BODY = f"""å°Šæ•¬çš„æ”¶ä»¶äººæ‚¨å¥½ï¼Œ

é€™æ˜¯ä¾†è‡ªæ‚¨çš„é›²ç«¯æ–°èæ‘˜è¦æ©Ÿå™¨äººï¼Œç‚ºæ‚¨æä¾› {current_date} çš„æ–°èé‡é»ã€‚

{formatted_news_string}

ç¥æ‚¨ä¸€å¤©æ„‰å¿«ï¼

æ‚¨çš„æ–°èæ‘˜è¦æ©Ÿå™¨äºº
"""

# --- å¯„ä¿¡å‡½æ•¸ ---
def send_email(sender, password, receiver, subject, body, attach_file=False, attachment_path=None):
    """
    ç™¼é€é›»å­éƒµä»¶çš„å‡½æ•¸ã€‚
    æ”¯æŒç´”æ–‡å­—å’Œé™„ä»¶ã€‚
    """
    # å‰µå»ºä¸€å€‹å¤šéƒ¨åˆ†éƒµä»¶ï¼Œé€™æ¨£å¯ä»¥åŒ…å«æ–‡æœ¬å’Œé™„ä»¶
    msg = MIMEMultipart()
    msg["From"] = sender
    msg["To"] = receiver
    msg["Subject"] = subject

    # æ·»åŠ éƒµä»¶æ­£æ–‡
    msg.attach(MIMEText(body, "plain", "utf-8")) # å¦‚æœæ˜¯ HTML å…§å®¹ï¼Œæ”¹ç‚º "html"

    # æ·»åŠ é™„ä»¶
    if attach_file and attachment_path:
        if not os.path.exists(attachment_path):
            print(f"è­¦å‘Š: é™„ä»¶æª”æ¡ˆ '{attachment_path}' ä¸å­˜åœ¨ã€‚å°‡ä¸ç™¼é€é™„ä»¶ã€‚")
        else:
            try:
                with open(attachment_path, "rb") as attachment:
                    part = MIMEBase("application", "octet-stream")
                    part.set_payload(attachment.read())
                    encoders.encode_base64(part) # é€²è¡Œ Base64 ç·¨ç¢¼

                    # è¨­å®šé™„ä»¶çš„æª”å
                    filename = os.path.basename(attachment_path)
                    part.add_header(
                        "Content-Disposition",
                        f"attachment; filename= {filename}",
                    )
                    msg.attach(part)
                print(f"é™„ä»¶ '{filename}' å·²æˆåŠŸæ·»åŠ åˆ°éƒµä»¶ã€‚")
            except Exception as e:
                print(f"æ·»åŠ é™„ä»¶å¤±æ•—: {e}")

    try:
        # å‰µå»ºä¸€å€‹å®‰å…¨çš„ SSL ä¸Šä¸‹æ–‡
        context = ssl.create_default_context()

        # é€£æ¥åˆ° SMTP ä¼ºæœå™¨ä¸¦ç™¼é€éƒµä»¶
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:
            server.starttls(context=context)  # å•Ÿå‹• TLS åŠ å¯†
            server.login(sender, password)
            server.sendmail(sender, receiver, msg.as_string())
        print(f"éƒµä»¶å·²æˆåŠŸç™¼é€ï¼")
    except smtplib.SMTPAuthenticationError as e:
        print(f"éƒµä»¶ç™¼é€å¤±æ•—: èªè­‰éŒ¯èª¤ã€‚è«‹æª¢æŸ¥ä½ çš„ç™¼ä»¶äººéƒµç®±å’Œæ‡‰ç”¨ç¨‹å¼å¯†ç¢¼æ˜¯å¦æ­£ç¢ºã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
    except smtplib.SMTPException as e:
        print(f"éƒµä»¶ç™¼é€å¤±æ•—: SMTP éŒ¯èª¤ã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
    except Exception as e:
        print(f"éƒµä»¶ç™¼é€å¤±æ•—: æœªçŸ¥éŒ¯èª¤ã€‚\néŒ¯èª¤è¨Šæ¯: {e}")

send_email(
    sender=SENDER_EMAIL,
    password=SENDER_PASSWORD,
    receiver=RECEIVER_EMAIL,
    subject=EMAIL_SUBJECT,
    body=EMAIL_BODY,
    attach_file=ATTACH_FILE,
    attachment_path=ATTACHMENT_PATH
)